{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from umap import UMAP\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "data_path = \"../data\"\n",
    "\n",
    "from models.cx_groups import Cx_groups\n",
    "from models.pca_clients import Cx_groups_post_pca \n",
    "from models.easy_pca import Easy_pca\n",
    "from scripts.optimizers_mp import k_means_optimizer\n",
    "from scripts.df_actions import remove_outliers\n",
    "\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "\n",
    "load_dotenv()\n",
    "sns.color_palette('colorblind')\n",
    "plt.style.use('Solarize_Light2')\n",
    "\n",
    "# Setting default DPI, pulling it from dotenv if it exists, setting it on 100 if not\n",
    "\n",
    "try:\n",
    "    pc_dpi = int(os.getenv('DPI'))\n",
    "except TypeError:\n",
    "    pc_dpi = 100\n",
    "if pc_dpi is None:\n",
    "    pc_dpi = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <i>Taking into account what RFM approach taught us and the clusters we extracted from the data :</i>\n",
    "\n",
    "# 1 : Statistics considering the clusters obtained via RFM\n",
    "# 2 : Delta Order / Delivery and its effects on customers' satisfaction.\n",
    "# 3 : Delta dist, is it a determining factor in the choice made by clients ?\n",
    "# 4 : PCA on selected variables for classification\n",
    "# 5 : Modelisations and early conclusions\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olist_clients_dataset = \"../final_datasets/olist_customers.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cx = pd.read_pickle(olist_clients_dataset)\n",
    "\n",
    "df_cx.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cx.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cx.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# <u>1 : Statistics considering the clusters obtained via RFM.</u>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>1.1 : Ratings across all the dataset:</u>\n",
    "\n",
    "<b><u>Goals : </u></b>\n",
    "\n",
    "&emsp;This will help to visualize how many people have left at least one Review, and if they commented it. We will see the involvement of customers, first across all the dataset. We call calculate the avg of all ratings to provide a reference/comparison point for ratings per cluster\n",
    "\n",
    "<b><u>Method : </u></b>\n",
    "\n",
    "&emsp;We will first assess the amount of customers that have rated and/or commented. We will calculate the average ratio for ratings and comments. It will be interesting to see, first, those metrics on the dataset, then applied to our first successful segmentation (k-means w/ k=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if people can comment without rating : \n",
    "\n",
    "commenters = df_cx[df_cx[\"has_commented\"] == True]\n",
    "print(f\"{len(commenters[commenters['rating_avg'] == np.nan])}\")\n",
    "\n",
    "del commenters  # Flush\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addlabels(x, y):\n",
    "    for i in range(len(x)):\n",
    "        plt.text(i, y[i], f\"{y[i]}\", ha=\"center\", bbox=dict(facecolor=\"white\", alpha=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No they cant, okay so cx who have posted a comment have to rate the order.\n",
    "\n",
    "ratings_avg_dswide = np.average(df_cx[df_cx[\"rating_avg\"].notna()][\"rating_avg\"].values.tolist())\n",
    "ratings_ratio_dswide = np.average(df_cx[\"rating_ratio\"])\n",
    "comment_ratio_dswide = np.average(df_cx[\"comment_ratio\"])\n",
    "\n",
    "rating_poster_dswide = len(df_cx[df_cx[\"has_rated\"] == True])\n",
    "comment_poster_dswide = len(df_cx[df_cx[\"has_commented\"] == True])\n",
    "no_rating = len(df_cx[df_cx[\"has_rated\"] == False])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(\n",
    "    ncols=1,\n",
    "    nrows=1,\n",
    "    figsize=(10, 6),\n",
    "    dpi=pc_dpi,\n",
    ")\n",
    "\n",
    "bars = {\"rating_poster\": rating_poster_dswide, \"comment_and_rate\": comment_poster_dswide, \"no_review\": no_rating}\n",
    "\n",
    "cmap_one = [\"#000331\", \"navy\", \"red\"]\n",
    "\n",
    "ax1.bar(x=list(bars.keys()), height=list(bars.values()), color=cmap_one)\n",
    "\n",
    "###\n",
    "# Titles/Lables\n",
    "addlabels(x=[cat for cat in bars.keys()], y=[pop for pop in bars.values()])\n",
    "ax1.set_ylabel(\"Population of group\")\n",
    "ax1.set_xlabel(\"Group\")\n",
    "ax1.tick_params(left=False)\n",
    "fig.suptitle(\"Amount of users by their method of rating\")\n",
    "#\n",
    "###\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;By design (Olist sharing mostly orders which have been subject to customer review) or by accident (very small non zero chance), the crushing majority of customers have rated their orders at least once (95211 out of 95922, or about 99.26% of customers).\n",
    "\n",
    "&emsp;There is also a considerable amount of customers who have assorted their reviews with a comment (You need to rate the order to comment it, at least, in this dataset, no commented order was unrated) : 39700 out of 95922 clients, which is about 41.39% of the total population.\n",
    "\n",
    "&emsp;Finally, a crushing minority of clients (711, which represents 0.74% of the dataset) have neither rated nor commented any of their orders. Due to the nature of the data, we can theorize that this concerns orders that have not been yet completed (delivered ?) at the time of SQL dump. We will include this in our report and inquire about those 711 customers.\n",
    "\n",
    "<hr>\n",
    "\n",
    "&emsp;We need to visualize at which ratio customers have reviewed and commented in average, but since most (but not all) customers have only placed one order, we can expect this number to quite close to 1, for ratings at least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(\n",
    "    ncols=1,\n",
    "    nrows=1,\n",
    "    figsize=(10, 6),\n",
    "    dpi=pc_dpi,\n",
    ")\n",
    "\n",
    "bars_ratios_dswide = {\"review_ratio\": ratings_ratio_dswide, \"comment_ratio\": comment_ratio_dswide}\n",
    "\n",
    "cmap_one = [\"#000331\", \"navy\"]\n",
    "\n",
    "ax1.bar(x=list(bars_ratios_dswide.keys()), height=list(bars_ratios_dswide.values()), color=cmap_one)\n",
    "\n",
    "###\n",
    "# Titles/Lables\n",
    "addlabels(x=[cat for cat in bars_ratios_dswide.keys()], y=[pop for pop in bars_ratios_dswide.values()])\n",
    "ax1.set_ylabel(\"Ratio (0-1)\")\n",
    "ax1.tick_params(left=False)\n",
    "fig.suptitle(\"Average rating and comment ratio, datasetwide\")\n",
    "#\n",
    "###\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;That was expected, this is in line with what we saw on the previous chart. Average ratio of ratings is close to 1 and comment ratio close to 0.4139 (our 41.39% from the comment group earlier).\n",
    "\n",
    "&emsp;We can conclude this analysis of the review ratio by stating that, being that close to 1 and seemingly almost mandatory for the order to be in the dataset, is of no use since it cannot efficiently help our clustering. We later drop this variable (keeping the boolean for now), but we suggest its use in the model chosen at the end of this analysis. According to this article : <a href=\"https://www.gwi.com/hubfs/Downloads/Brand_Discovery-2019.pdf\">this article</a>, in 2019, 47% of e-commerce customers leave a review each month. It would be necessary to see if that proportion is similar in the whole Olist database or it if keeps being that high.\n",
    "\n",
    "<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "&emsp;Let's take a look at the rating distribution in the dataset and the average rating left by customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rounding up to 1/1.5/2/2.5/3/3.5/4/4.5/5\n",
    "rounded_list = []\n",
    "\n",
    "og_list = df_cx[df_cx[\"rating_avg\"].notna()][\"rating_avg\"].values.tolist()\n",
    "\n",
    "for rating in og_list:\n",
    "    rounded_list.append(round(rating * 2) / 2)\n",
    "\n",
    "uniques = []\n",
    "for rating in rounded_list:\n",
    "    if rating not in uniques:\n",
    "        uniques.append(rating)\n",
    "\n",
    "uniques.sort()\n",
    "\n",
    "print(uniques)\n",
    "\n",
    "# Nice, feels like im reinventing the wheels there but that works\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_dswide = dict.fromkeys(uniques)\n",
    "\n",
    "for rating in ratings_dswide:\n",
    "    ratings_dswide[rating] = rounded_list.count(rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(\n",
    "    ncols=1,\n",
    "    nrows=1,\n",
    "    figsize=(10, 6),\n",
    "    dpi=pc_dpi,\n",
    ")\n",
    "\n",
    "colors = [\"black\", \"dimgray\", \"darkred\", \"red\", \"yellow\", \"steelblue\", \"royalblue\", \"navy\", \"#000331\"]\n",
    "\n",
    "ratings = [str(number) for number in np.arange(1, 5.5, 0.5)]\n",
    "amount = rating\n",
    "ax1.bar(x=ratings, height=list(ratings_dswide.values()), color=colors)\n",
    "\n",
    "###\n",
    "# Titles/Lables\n",
    "addlabels(x=[rating for rating in ratings_dswide.keys()], y=[pop for pop in ratings_dswide.values()])\n",
    "#\n",
    "###\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;Looks like there is an overwhelming number of very high ratings (5 = half of the customers). This looks overly optimistic but it is not unlikely as the study quoted earlier states that satisfied customers are more likely to give a review. Negative ones too but less so, <a href=\"https://findstack.com/online-review-statistics/\">according to this study</a> (point 25).\n",
    "\n",
    "&emsp;So we can expect the average overall rating to be quite high. Let's check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average for the whole dataset = {ratings_avg_dswide}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so we have our reference value, now we can use it as a baseline to determine clusters characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>1.2 : Statistics using the clusters attributed by k-means with k=4:</u>\n",
    "\n",
    "<b><u>Goals :</u></b>\n",
    "\n",
    "&emsp;We might be able to distinguish different characteristics from cluster to cluster, hence giving us a way to compare and evaluate the relevance of a given variable. (Which could otherwise be done using SHAP)\n",
    "\n",
    "<b><u>Method :</u></b>\n",
    "\n",
    "&emsp;For starters, Let's use names of clusters and not their numbers. It will make more sense to talk about people and not numbers.\n",
    "\n",
    "<br>\n",
    "\n",
    "We will use a radar plot to represent the most important statistics and their average per group :\n",
    "- Delta Days\n",
    "- Average Rating\n",
    "- Delta Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Min Max Scaler doesnt support timedeltas, so we need to convert timedeltas to ints (days)\n",
    "\n",
    "def get_delta_days(row):\n",
    "    try:\n",
    "        return int(row[\"expected_reality\"].days)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cx[\"delta_days\"] = df_cx.apply(get_delta_days, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler(feature_range=(0, 5))\n",
    "\n",
    "subset = [\"rating_avg\", \"delta_days\", \"distance_cx_seller\", \"recency\", \"frequency\"]\n",
    "scaled_subset = [\n",
    "    \"scaled_rating_avg\", \"scaled_delta_days\",\n",
    "    \"scaled_distance_cx_seller\", \"scaled_recency\",\n",
    "    \"scaled_frequency\"\n",
    "    ]\n",
    "\n",
    "keepcols = [\"rating_avg\", \"delta_days\", \"distance_cx_seller\", \"recency\", \"frequency\", \"k_cluster_name\"]\n",
    "\n",
    "df_cx_mms = df_cx[keepcols].copy()\n",
    "\n",
    "df_cx_mms[scaled_subset] = mms.fit_transform(df_cx_mms[subset].to_numpy())\n",
    "\n",
    "df_cx_mms.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "investor_group = Cx_groups(cluster_name=\"investors\", dataframe=df_cx_mms[df_cx_mms[\"k_cluster_name\"] == \"investors\"])\n",
    "early_m_group = Cx_groups(cluster_name=\"early_majority\", dataframe=df_cx_mms[df_cx_mms[\"k_cluster_name\"] == \"early_majority\"])\n",
    "late_m_group = Cx_groups(cluster_name=\"late_majority\", dataframe=df_cx_mms[df_cx_mms[\"k_cluster_name\"] == \"late_majority\"])\n",
    "lagg_group = Cx_groups(cluster_name=\"laggards\", dataframe=df_cx_mms[df_cx_mms[\"k_cluster_name\"] == \"laggards\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_inv = investor_group.store_radar()\n",
    "em_radar = early_m_group.store_radar()\n",
    "lm_radar = late_m_group.store_radar()\n",
    "lagg_radar = lagg_group.store_radar()\n",
    "\n",
    "# Let's superpose the radars : (Class Cx Group saves the trace)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatterpolar(investor_group.trace))\n",
    "fig.add_trace(go.Scatterpolar(early_m_group.trace))\n",
    "fig.add_trace(go.Scatterpolar(late_m_group.trace))\n",
    "fig.add_trace(go.Scatterpolar(lagg_group.trace))\n",
    "\n",
    "colors = [\"#000331\", \"navy\", \"royalblue\", \"red\"]\n",
    "\n",
    "title = \"Newly created stats, MinMaxed for each cluster determined during RFM segmentation Each cluster\"\n",
    "\n",
    "fig.update_layout(\n",
    "  title=title,\n",
    "  polar=dict(\n",
    "    radialaxis=dict(\n",
    "      visible=True,\n",
    "      range=[0, 5]\n",
    "    )),\n",
    "  showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "investor_group.get_standard_stats()\n",
    "investor_group.standard_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagg_group.get_standard_stats()\n",
    "lagg_group.standard_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cx.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;As we can see here and in the plots above, the ratings are unexpectedly high and the standard deviation very low. On our sample, customers are overall satisfied/very satisfied. This behaviors with a very high mean and average, and very low std, even between the groups, is not beneficial pour any clustering model : if there are no noticeable differences between the clients, it will prove difficult to propose a comprehensive clustering mean to help Olist with customer segmentation. If the gain extracted from this new variable does not improve the model but on the contrary, flaws it, we will recommend the simple RFM approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cx[\"rating_avg\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cx[\"rating_avg\"].quantile([0.1, 0.25, 0.50, 0.75, 0.90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(\n",
    "    ncols=1,\n",
    "    nrows=1,\n",
    "    figsize=(8, 2),\n",
    "    dpi=pc_dpi,\n",
    ")\n",
    "\n",
    "g = sns.boxplot(x=\"rating_avg\", data=df_cx, ax=ax1)\n",
    "\n",
    "###\n",
    "# Titles/Lables\n",
    "fig.suptitle(\"Rating repartition across the dataset\")\n",
    "#\n",
    "###\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so more than 75% of the customer sample did not rate, in average, under 4. If there is something better to use as a satisfaction indicator, we'll take it. Meanwhile, let's investigate on this sub-sample of customers : the ones that have given a 2.5 rating or worse in average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cx_sample = df_cx[df_cx[\"rating_avg\"] <= 2.5]\n",
    "\n",
    "print(f\"{len(df_cx_sample)} have rated under 2.5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cx_sample[\"k_cluster_name\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;Ok so there's a lot of every one based from our previous clustering. Most important groups are the two majorities (which represent both around 32/35%), which was to be expected. What is interesting is to see that our \"laggards\" from the previous segmentation (which represented 18% of the dataset) are more or less as important here as the group we called \"investors\" in the first clustering. While they both represent around 20%, we have almost an equal amount of both. Which is interesting as we did not expect the \"investor\" group to give low ratings, on the contrary. This is a good indication that we lacked information in our RFM clustering and what we obtained during the feature engineering will likely improve the initial segmentation. In the rest of the analysis, we will also compare this group specifically and maybe diagnose the nature of this \"low\" rating.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# <u>2 : Delta Order / Delivery and its effects on customers' satisfaction.</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>2.1 : Delta Order / Delivery : choice of variable.</u>\n",
    "\n",
    "&emsp;While we have two timedelta variables for this indicator, there is one which will likely not result in an improvement for the clustering.\n",
    "Indeed, the raw value of ∆Order/Delivery might not be as useful as expected, and ∆expected/delivery would be much more precise.\n",
    "<br> <br>\n",
    "&emsp;Let's say I pre-order something (P1) on the internet that's supposed to come out in 1 month, and I order another thing (P2) that I expect in a week. If every thing goes according to what has been indicated, I will receive P1 in a month and P2 in a week, those two orders won't have the same ∆order/delivery and that will impact negatively P1 (∆ = 1 month) over P2 (∆ = 1 week).<br>\n",
    "&emsp;Now the ∆Expected/Delivered takes into account the initial expectation. So in the case all is fine and on time, ∆ will be 0 for both P1 and P2, a negative ∆ will indicate that it was delivered early and a positive one, late. This is likely way more precise.\n",
    "<br> <br>\n",
    "&emsp;We will use ∆expected/delivery from now on. Let's see it this has an impact on Cx satisfaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = df_cx[df_cx[\"delta_days\"].notna()][\"delta_days\"].unique()\n",
    "\n",
    "x_height = dict.fromkeys(x_axis)\n",
    "\n",
    "for x in x_height:\n",
    "    x_height[x] = np.average(df_cx[(df_cx[\"delta_days\"] == x) & (df_cx[\"rating_avg\"].notna())][\"rating_avg\"].values.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(\n",
    "    ncols=1,\n",
    "    nrows=1,\n",
    "    figsize=(8, 4),\n",
    "    dpi=pc_dpi,\n",
    ")\n",
    "\n",
    "ax1.scatter(x=list(x_height.keys()), y=list(x_height.values()))\n",
    "\n",
    "###\n",
    "# Titles/Lables\n",
    "ax1.set_xlabel(\"Delta Days between expected and actual delivery\")\n",
    "ax1.set_ylabel(\"Average Rating for a given Delta Day\")\n",
    "fig.suptitle(\"Average rating by Days elapsed between expected and actual delivery\")\n",
    "#\n",
    "###\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation :\n",
    "\n",
    "&emsp;As expected, clients' ratings are related to the punctuality of Olist. If the order arrives early or on time, clients' ratings are high, and this trend inverses as delta=0 is reached. People are more dissatisfied for every day Olist is late. The +30 days relatively high average bump in rating can probably be attributed to the lack of orders delivered beyond 30 days. Let's check if our dataset containing our relatively dissatisfied customers contains more clients that have been delivered late."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_eot_all = len(df_cx[df_cx[\"early_on_time\"] == True])\n",
    "amount_eot_sample = len(df_cx_sample[df_cx_sample[\"early_on_time\"] == True])\n",
    "\n",
    "percentage_all = (amount_eot_all / len(df_cx)) * 100\n",
    "percentage_sample = (amount_eot_sample / len(df_cx_sample)) * 100\n",
    "\n",
    "print(f\"There is {percentage_all}% of who have been delivered on time on the whole dataset\")\n",
    "print(f\"There is {percentage_sample}% of who have been delivered\\\n",
    " on time amongst the clients who have rated 2.5 or less (avg)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation :\n",
    "&emsp;There is indeed a great difference between the sample of dissatisfied customers and the whole dataset.\n",
    "90.8% of the clients have received their orders early or on time on the whole dataset and just 58.2% of the clients for the sample containing people who have left a rating of 2.5 or less (avg.). We can safely say that a big part of the dissatisfied customers were disappointed because they were not delivered on time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# <u>3 : Delta dist, is it a determining factor in the choice made by clients ?</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>3.1 : Number of orders in function of distance cx/seller</u>\n",
    "\n",
    "### How ?\n",
    "\n",
    "&emsp;We will take the min/max value of `distance_cx_seller` and create \"distance blocks\" (array (min, max, step)) where we will count the number of orders made by clients inside the current range (`num_orders`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There is {df_cx['distance_cx_seller'].isna().sum()} NA values in the dataset\")\n",
    "print(f\"The Maximum distance is {df_cx['distance_cx_seller'].max()} Kms between seller and cx\")\n",
    "\n",
    "df_cx[\"distance_cx_seller\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;It seems we have a lot of NA (which we will fill with the median, here 434.45 and change). Let's also plot the distribution to get a better sense of the extremes, which we will include as \"more/less than whisker\" to avoid over representation of the extremes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = df_cx[df_cx[\"distance_cx_seller\"].notna()][\"distance_cx_seller\"].values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(\n",
    "    ncols=1,\n",
    "    nrows=1,\n",
    "    figsize=(8, 4),\n",
    "    dpi=pc_dpi,\n",
    ")\n",
    "\n",
    "ax1.boxplot(x=distances, vert=False, showbox=True, showmeans=True, widths=(0.4))\n",
    "\n",
    "###\n",
    "# Titles/Lables\n",
    "ax1.set_xlabel(\"Number of average kilometers between customer and seller\")\n",
    "fig.suptitle(\"Representation of clients based on their average distance to seller when order was placed\")\n",
    "ax1.set_yticks([])\n",
    "#\n",
    "###\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation :\n",
    "\n",
    "&emsp;Looks like most people order between 0 and 2k Kms, lets zoom on this area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(\n",
    "    ncols=1,\n",
    "    nrows=1,\n",
    "    figsize=(8, 4),\n",
    "    dpi=pc_dpi,\n",
    ")\n",
    "\n",
    "ax1.boxplot(x=distances, vert=False, showbox=True, showmeans=True, widths=(0.4))\n",
    "\n",
    "###\n",
    "# Titles/Lables\n",
    "ax1.set_xlabel(\"Number of average kilometers between customer and seller\")\n",
    "fig.suptitle(\"Representation of clients based on their average distance to seller when order was placed\\\n",
    "\\nzoom on less than 2000\")\n",
    "ax1.set_xlim(left=(-100), right=(2000))\n",
    "ax1.set_xticks(range(0, 2000, 200))\n",
    "ax1.set_yticks([])\n",
    "#\n",
    "###\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;Let's fillna with the median, get 10/90% values and take a peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cx[\"distance_cx_seller\"] = df_cx[\"distance_cx_seller\"].fillna(df_cx[\"distance_cx_seller\"].median())\n",
    "\n",
    "distances_post_fill = df_cx[df_cx[\"distance_cx_seller\"].notna()][\"distance_cx_seller\"].values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles_distance = df_cx[\"distance_cx_seller\"].quantile([0.10, 0.90])\n",
    "\n",
    "llim = round(quantiles_distance[0.10], ndigits=4)  # Rounded to meter\n",
    "rlim = round(quantiles_distance[0.90], ndigits=4)  # Rounded to meter\n",
    "\n",
    "print(f\"10% under {llim} Kms, 90% under {rlim} Kms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(\n",
    "    ncols=1,\n",
    "    nrows=1,\n",
    "    figsize=(8, 4),\n",
    "    dpi=pc_dpi,\n",
    ")\n",
    "\n",
    "ax1.boxplot(x=distances_post_fill, vert=False, showbox=True, showmeans=True, widths=(0.4), sym=\"\")\n",
    "\n",
    "###\n",
    "# Titles/Lables\n",
    "ax1.set_xlabel(\"Number of average kilometers between customer and seller\")\n",
    "fig.suptitle(\"Representation of clients based on their average distance to seller when order was placed\\\n",
    "\\nzoom on less than 2000, fliers removed\")\n",
    "ax1.set_xlim(left=(-100), right=(2000))\n",
    "ax1.set_xticks(range(0, 2000, 200))\n",
    "ax1.set_yticks([])\n",
    "#\n",
    "###\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;Filling NA by the median didn't impact negatively our data. Let's set our range to : under 50 kms, above 1500 kms with step 100kms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_range = np.arange(50, 1551, 100)\n",
    "\n",
    "distance_dict = dict.fromkeys(distance_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous = 0\n",
    "for distance in distance_range:\n",
    "    if distance != distance_range[-1]:\n",
    "        amnt_orders = df_cx[(df_cx[\"distance_cx_seller\"] > previous)\n",
    "                        & (df_cx[\"distance_cx_seller\"] < distance)][\"num_orders\"].sum()\n",
    "\n",
    "    else:  # Last distance of distance range, just need \"more than distance\"\n",
    "        amnt_orders = df_cx[(df_cx[\"distance_cx_seller\"] > 1550)][\"num_orders\"].sum()\n",
    "\n",
    "    distance_dict[distance] = amnt_orders        \n",
    "    previous = distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addlabels_ranged100(x, y):\n",
    "    for i in range(len(x)):\n",
    "        plt.text(i * 100 + 50, y[i], f\"{y[i]}\", ha=\"center\", bbox=dict(facecolor=\"white\", alpha=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(\n",
    "    ncols=1,\n",
    "    nrows=1,\n",
    "    figsize=(8, 6),\n",
    "    dpi=pc_dpi,\n",
    ")\n",
    "\n",
    "magma = plt.get_cmap(\"magma\").reversed()\n",
    "\n",
    "height_normalized = [value / max(list(distance_dict.values())) for value in list(distance_dict.values())]\n",
    "\n",
    "colors = magma(height_normalized)\n",
    "\n",
    "ax1.bar(x=list(distance_dict.keys()), height=list(distance_dict.values()), width=90, color=colors)\n",
    "\n",
    "###\n",
    "# Titles/Lables\n",
    "ax1.set_xticks(distance_range)\n",
    "ax1.set_xlabel(\"Average distance from seller\")\n",
    "addlabels_ranged100(x=[distance for distance in distance_dict.keys()], y=[amnt for amnt in distance_dict.values()])\n",
    "#\n",
    "###\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Note : As we drew our limits between 10% and 90% of the dataset, the high amount of order above 1550 kms is to be expected as it represents 10% of the dataset</i>\n",
    "\n",
    "#### Observations :\n",
    "\n",
    "&emsp;This graph shows that, indeed, people orders are more often than not to seller that are relatively close, orders from seller above 550 kms away begin to drop quite quickly. We can hypothesize that expected delivery time is shorter for shorter distances and clients prefer to get an item quickly. Although there is a non negligible part of orders ranging from 650km and above, it is possible that it is for specific products that have no alternatives locally or from customers who live in more remotes part of Brazil.\n",
    "<br> <br>\n",
    "&emsp;This is a more interesting variable than expected. As we know, alternatives like Amazon for example use a subscription method like Prime to get rid of delivery fees altogether. It hints that it is not the case here or there is an incentive (fee, time etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>4 : PCA on selected variables for classification</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>4.1 : Variable pre-selection and conversions</u>\n",
    "\n",
    "### Why ?\n",
    "\n",
    "&emsp;PCA will work better on certain data, while I have coded a layer of abstraction above it to make it easier to use and streamline the process, we still need to select our variables accordingly.\n",
    "\n",
    "- PCA works on numerical values, so we need a few conversions :\n",
    "    - Boolean values must go from True/False to 1/0\n",
    "    - Datetimes and timedeltas must be converted in 1. an understandable way for the humans 2. an understandable way for the machine, so depending on the case we will use days as the main metric (most_recent_order is a repetition of recency, so we will just drop it)\n",
    "    - Cluster indicators from previous clustering will also be dropped as well as any information regarding this (cluster name etc.)\n",
    "    - As stated, delta_delivery is lacking compared to expected/reality, which we have already converted to delta_days, so we'll drop both and keep \"delta_days\"\n",
    "    - Distance cx/seller proved to be an interesting variable so we'll keep it.\n",
    "    - For now we will also remove the lat/lon of all clients.\n",
    "    - customer_uid is purely informative and will be dropped to be re added after (to identify who's who)\n",
    "    - order_id_list is also purely informative, it will not help the model in any way\n",
    "\n",
    "<i>By default, converting a boolean column into a int column will do the 1/0 conversion for us, not necessary to reinvent the wheel there</i>\n",
    "\n",
    "&emsp;We will begin by using IQR method to remove outliers from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_creation(row):\n",
    "    \"\"\"\n",
    "    Returns the difference between now and the most ancient order\n",
    "    Most ancient order is understood as the account creation date for lack\n",
    "    of more specific info\n",
    "    \"\"\"\n",
    "\n",
    "    now = np.datetime64(\"now\")\n",
    "    then = row[\"most_ancient_order_dt\"]\n",
    "    delta = now - then\n",
    "    delta = np.timedelta64(delta, \"D\")\n",
    "    return delta.astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first convert \"most_ancient_order_dt\", which we assimilate to the account creation. We want the number of days between then and now\\\n",
    "We'll keep the col for the stability analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cx[\"delta_creation\"] = df_cx.apply(delta_creation, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cx[\"has_rated\"] = df_cx[\"has_rated\"].astype(int)\n",
    "df_cx[\"has_commented\"] = df_cx[\"has_commented\"].astype(int)\n",
    "df_cx[\"early_on_time\"] = df_cx[\"early_on_time\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cx.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IQR\n",
    "print(\"Before\", len(df_cx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_iqr = [\n",
    "    \"num_orders\", \"rating_avg\", \"distance_cx_seller\",\n",
    "    \"delta_days\", \"delta_creation\"\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df_cx.columns:\n",
    "    if column in target_iqr:\n",
    "        remove_outliers(column_eval=column, df=df_cx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"After\", len(df_cx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropcols = [\n",
    "    \"customer_uid\", \"cluster_kmeans_4\", \"cluster_DBSCAN\",\n",
    "    \"k_cluster_name\", \"delta_delivery\", \"expected_reality\",\n",
    "    \"order_id_list\", \"most_recent_order_dt\", \"lat\", \"lon\",\n",
    "    \"most_ancient_order_dt\",\n",
    "    ]\n",
    "\n",
    "df_model = df_cx.drop(columns=(dropcols), errors=\"ignore\")\n",
    "\n",
    "df_model.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>4.2 : PCA and interpretations : </u>\n",
    "\n",
    "<i>For more info about the class Easy_pca, documentation is provided in the model as docstring</i>\n",
    "\n",
    "- First we want to get a scree plot to know about the principal components we need.\n",
    "- Then we'll want to take a look at the correlation circles to have a better grasp on what individual selected PC is.\n",
    "- For ease of use, we can also display a table with the coefficients of each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epca_model = Easy_pca(dataset=df_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = epca_model.get_scree_plot(show=False)\n",
    "\n",
    "fig.set_dpi(pc_dpi)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(8)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we get around 90% cumulative inertia with PC1 through PC5. Let's take a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = epca_model.display_circles(couple_pc=(0, 1), show=False)\n",
    "\n",
    "fig.set_dpi(pc_dpi)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(5)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = epca_model.display_circles(couple_pc=(2, 3), show=False)\n",
    "\n",
    "fig.set_dpi(pc_dpi)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(5)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = epca_model.display_circles(couple_pc=(3, 4), show=False)\n",
    "\n",
    "fig.set_dpi(pc_dpi)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(5)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epca_model.biplot((0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epca_model.biplot((2, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epca_model.biplot((3, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contribution = epca_model.show_contribution(lim_pc=5)\n",
    "\n",
    "df_contribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have there the coefficients of each variable, to get a better grasp on each one and to see what subset of variables contribute the most, we will use abs values for each PC, and rename it as we go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(df_contribution[\"PC1\"]).sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, PC1 represents Time. The frequency is positively correlated with PC1 while delta_creation and the recency are negatively correlated. It is basically the time since last order.\n",
    "- Proposed name : time_impact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(df_contribution[\"PC2\"]).sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there is more of a mix in PC2, we can clearly see that it represents the customer's involvement with the order : the variables on ratings and comments are both very important in this PC. While we see delta_days scoring quite high, we already established it was highly correlated with the ratings and user's involvement.\n",
    "- Proposed name : general_involvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(df_contribution[\"PC3\"]).sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While PC2 and PC3 might seem similar, PC3 seems entirely focused on ratings and seems to ignore comments. early_on_time and delta_days score also high, likely for the same reason as PC2. Taking the real values (not abs), we can see that rating avg. and comment ratio are anti-correlated to the variable \"delta_days\", it is interpretable as general dissatisfaction : when the value of delta days climbs, the ratings fall, as we have established in 2.1\n",
    "\n",
    "- Proposed name : rating_delay / dissatisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(df_contribution[\"PC4\"]).sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The absolute values of PC3 and PC4 are very similar, for a very good reason : while PC3 represents discontentment, PC4 represents satisfaction : delta days is highly negatively correlated with PC4, while rating average and early/on time are highly positively correlated with PC4. If delta days is low, and the order is on time or early, cx is happy.\n",
    "\n",
    "- Proposed name : overall_satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(df_contribution[\"PC5\"]).sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This PC is highly correlated with 3 variables : monetary, num_orders and distance_cx_seller (negatively) : we established in 3.1 that order amounts decreased with the distance so it makes sense. We can think of PC5 as a variable that describes the volume of transaction and the overall sum of money people spend on Olist.\n",
    "\n",
    "- Proposed_name : value_and_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_keep = [\"PC1\", \"PC2\", \"PC3\", \"PC4\", \"PC5\"]\n",
    "\n",
    "df_model_pca = epca_model.pcframe[pc_keep]\n",
    "\n",
    "df_model_pca.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = dict.fromkeys(pc_keep)\n",
    "\n",
    "rename_dict[\"PC1\"] = \"time_impact\"\n",
    "rename_dict[\"PC2\"] = \"general_involvment\"\n",
    "rename_dict[\"PC3\"] = \"overall_discontentment\"\n",
    "rename_dict[\"PC4\"] = \"overall_satisfaction\"\n",
    "rename_dict[\"PC5\"] = \"value_and_volume\"\n",
    "\n",
    "df_model_pca = df_model_pca.rename(columns=rename_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_pca.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving forward we will use this dataset (same index) for clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>5 : Modelizations of adjusted parameters and exports</u> :\n",
    "\n",
    "- From what the exploratory analysis revealed, customer satisfaction is largely based on punctuality from Olist. The distance also plays an important role. So, before the modelization. The early conclusion is that improvements must be done on those 2 factors :\n",
    "    - The first by improving the reliability of shipping\n",
    "    - The second by connecting more local sellers or opening warehouses in areas that are too remote for most sellers, as we saw that distance played a big role on the amount of orders and the repeat of orders (PCA)\n",
    "- We will, as we did with the RFM variables, try to cluster the customers based on the data we gathered post-PCA.\n",
    "    - Will be used : K-means and DBSCAN, we will not use Agglomerative clustering for the same reason we did not use it for the RFM approach, it is too resource hungry on large datasets\n",
    "- We will choose the best clustering algorithm with the best hyperparameter(s) and take a broader look the clusters themselves, using the real values we had before applying a PCA.\n",
    "- We will export the final dataset and move on to another document solely focused on maintenance of the chosen algorithm. <br><br>\n",
    "<b><u>Why ?</u></b> : This notebook is quite heavy a resource consuming. We will take the maintenance as a separate document to avoid :\n",
    "\n",
    "- 1 : Overusing the kernel which is already pretty full and will execute slowly on different setups (native jupyter, jupter-lab, vscode etc.)\n",
    "- 2 : A logic split between the interpretation, which can be changed if new data appears and disturbs the clusters, and the maintenance, which should be executed independently once the right algorithm and hyperparameter(s) have been chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>5.1 : K-Means optimization</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_pca.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(2, 10)\n",
    "\n",
    "k_means_optimizer(data=df_model_pca, k_range=k_range)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this approach, 5 | 6 Clusters seems to be the way to go, it maximizes the Silhouette Score while having an acceptable SSE\n",
    "Trying 6 first as it has the best Sil Score, otherwise, 5 \"might\" be a bit more explainable, we'll see in the groups population, we will iterate 5-6 if there's a cluster with less than 1000 customers or so.\n",
    "\n",
    "-- > 5 is more global, 6 does not seem to cluster correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=5)\n",
    "y_predicted = km.fit_predict(df_model_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_pca[\"cluster_km\"] = y_predicted\n",
    "df_cx[\"cluster_km\"] = y_predicted  # Index was kept between the dimsensionnal reductions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 : DBSCAN Clustering :\n",
    "\n",
    "&emsp;We will also use DBSCAN with the same idea as RFM #4.2, with min points as dimension + 1 (4)\n",
    "&emsp;Epsilon can be determined using k neighbors. Using a graph to represent the avg distance between a point and its k-neighbors (here 4 : dimension + 1). Zooming in and using the elbow method help us to focus on the best potential epsilon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors_matrix = df_model_pca.drop(columns=[\"cluster_km\"]).to_numpy()\n",
    "nneighbors = NearestNeighbors(n_neighbors=4, n_jobs=-1)  # dataset dim + 1\n",
    "\n",
    "nneighbors.fit(X=neighbors_matrix)\n",
    "\n",
    "distances, potential_eps = nneighbors.kneighbors(neighbors_matrix)\n",
    "\n",
    "distances = np.sort(distances, axis=0)\n",
    "distances_plot = distances[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(\n",
    "    ncols=1,\n",
    "    nrows=1,\n",
    "    figsize=(16, 8),\n",
    "    dpi=pc_dpi,\n",
    ")\n",
    "\n",
    "ax1.plot(distances_plot)\n",
    "\n",
    "###\n",
    "# Titles/Lables\n",
    "ax1.set_xlabel(\"Object\")\n",
    "ax1.set_ylabel(\"k distance\")\n",
    "fig.suptitle(\"Points sorted by distance - Neighbors = 6\")\n",
    "#\n",
    "###\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets innovate a bit and use plotly to zoom in\n",
    "\n",
    "fig = px.line(distances_plot)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Around eps = 1.1 | 1.2 seems to be the tipping point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = DBSCAN(eps=1.15, min_samples=6, n_jobs=-1)\n",
    "\n",
    "y_predict_dbs = dbs.fit_predict(df_model_pca.drop(columns=[\"cluster_k4\", \"cluster_DBSCAN\"], errors=\"ignore\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_pca[\"cluster_DBSCAN\"] = y_predict_dbs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_pca[\"cluster_DBSCAN\"].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Likely :\n",
    "Theres a lot more clusters than Kmeans. <br>\n",
    "Since the dataset seems linearly separable, DBSCAN doesn't do a great job at clustering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>5.3 : Observations of clustering both with PCA applied and using UMAP :</u>\n",
    "\n",
    "- Why not UMAP earlier ? <br>\n",
    "\n",
    "&emsp;While it is very good at dimensional reduction, it makes the axes hard to interpret. It helps visualizing but the more robust explanation will be through radars of the average and median of each group.\n",
    "\n",
    "- How ?\n",
    "\n",
    "&emsp;We will use both radar charts to plot the average and/or median client/cluster and UMAP to reduce the dimensions from 6 to 3, making it possible to visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_pca.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_pca_no_dbs = df_model_pca.drop(columns=[\"cluster_DBSCAN\"], errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_zero = Cx_groups_post_pca(dataframe=df_model_pca_no_dbs, k_group=0, cluster_col=\"cluster_km\")\n",
    "k_one = Cx_groups_post_pca(dataframe=df_model_pca_no_dbs, k_group=1, cluster_col=\"cluster_km\")\n",
    "k_two = Cx_groups_post_pca(dataframe=df_model_pca_no_dbs, k_group=2, cluster_col=\"cluster_km\")\n",
    "k_three = Cx_groups_post_pca(dataframe=df_model_pca_no_dbs, k_group=3, cluster_col=\"cluster_km\")\n",
    "k_four = Cx_groups_post_pca(dataframe=df_model_pca_no_dbs, k_group=4, cluster_col=\"cluster_km\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_zero = k_zero.store_radar()\n",
    "radar_one = k_one.store_radar()\n",
    "radar_two = k_two.store_radar()\n",
    "radar_three = k_three.store_radar()\n",
    "radar_four = k_four.store_radar()\n",
    "\n",
    "# Let's superpose the radars : (Class Cx Group saves the trace)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatterpolar(k_zero.trace))\n",
    "fig.add_trace(go.Scatterpolar(k_one.trace))\n",
    "fig.add_trace(go.Scatterpolar(k_two.trace))\n",
    "fig.add_trace(go.Scatterpolar(k_three.trace))\n",
    "fig.add_trace(go.Scatterpolar(k_four.trace))\n",
    "\n",
    "title = \"Stats of PCA vars (min maxed), clusters determined by k-means w/ k=4 on pca dataset\"\n",
    "\n",
    "fig.update_layout(\n",
    "  title=title,\n",
    "  polar=dict(\n",
    "    radialaxis=dict(\n",
    "      visible=True,\n",
    "      range=[0, 10]\n",
    "    )),\n",
    "  showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_pca[\"cluster_km\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;There's a cluster with around 650 clients, we can safely classify them in the atypical data category. Likely the result of an input error or an atypical behavior. Those are clients that we cannot interpret. <br><br>\n",
    "&emsp;We can see at first glance than a cluster containing around 7000 clients displays an average discontent higher than the other clusters. It can be seen as clients who are not satisfied with Olist/had a bad experience on the site. <br><br>\n",
    "&emsp;A group that is less distinguishable with those variables but still very important is the cluster that shares a lot of common stats with the two other majorities, except `time_impact` which is way higher in avg. than the other clusters. It points to very recent clients as `time_impact` (PC1) is negatively correlated with the variables that are used to determine the age of the account (namely the recency, and delta_creation, which is the agreed upon data pointing towards the first order of the account) higher values in these variables indicate that the account is recent and/or used recently.This is a group we must fidelize.<br><br>\n",
    "&emsp;We also have two majorities sharing the same stats. in avg., maj1 is remarkable as it has less involvement and less satisfaction than maj2.\n",
    "\n",
    "<i>Note : Cluster names cannot be given here as the re exec of KMeans will not always result the same cluster_number, so rerunning the script will give different numbers to clusters.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use UMAP to try and visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = UMAP(n_components=3, n_jobs=-1)\n",
    "\n",
    "df_umap = df_model_pca[[\n",
    "    \"time_impact\", \"general_involvment\", \"overall_discontentment\",\n",
    "    \"overall_satisfaction\", \"value_and_volume\", \"cluster_km\"\n",
    "    ]].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = reducer.fit_transform(df_umap.drop(columns=[\"cluster_km\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = pd.DataFrame(embedding)\n",
    "\n",
    "df_reduced[\"cluster_km\"] = df_umap[\"cluster_km\"].astype(str)  # Index kept, convert to str for plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_style = {\n",
    "    \"size\": 5,\n",
    "    }\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    data_frame=df_reduced, x=0,\n",
    "    y=1, z=2, color=\"cluster_km\",\n",
    "    width=4 * pc_dpi, height=3 * pc_dpi,\n",
    "    )\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    margin=dict(l=40, r=40, t=40, b=40),\n",
    "    title=\"Visualisation of dataset using UMAP reducer\",\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=marker_style)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;Even though UMAP abstracted the variables we can see that indeed, the clusters we associated to unsatisfied customers is clearly visible. As well the the atypicals. The two majorities are well defined and we can see that the group we associated with the new customers is a sort of an extension of the two large majorities.<br><br>\n",
    "&emsp;We will study in details those groups before studying the maintenance suggestions.\n",
    "\n",
    "<br>We can go back to the original dataset and remove the clusters defined in RFM.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cx.drop(columns=[\"cluster_kmeans_4\", \"cluster_DBSCAN\", \"k_cluster_name\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cx.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cx.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cx.columns\n",
    "df_model_pca_no_dbs[\"most_ancient_order_dt\"] = df_cx[\"most_ancient_order_dt\"]  # Indexes are kept\n",
    "df_model_pca_no_dbs.drop(columns=[\"cluster_km\"]).to_pickle(path=\"../pickles/dataset_pca_maintenance.pkl\")  # Export for maintenance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To name the clusters we can go with\n",
    "- Atypical (atypc_cx)\n",
    "- Unsatisfied (unsat_cx)\n",
    "- Majority 1 (maj_1)\n",
    "- Majority 2 (maj_2)\n",
    "- New customers (new_cx)\n",
    "\n",
    "-- \n",
    "\n",
    "We cannot predict which x number will be y group name so we will use the input method and use the radars to reference the correct groups\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Important : Maj 1 is the less satisfied majority, it will be important later !\n",
    "\n",
    "atypc_cx = int(input(\"Atypical : \"))\n",
    "new_cx = int(input(\"New customers : \"))\n",
    "maj1 = int(input(\"Maj1 : \"))\n",
    "maj2 = int(input(\"Maj2 : \"))\n",
    "unsat_cx = int(input(\"Unsatisfied : \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_clusters = {\n",
    "    atypc_cx: \"atypical\", new_cx: \"new_client\",\n",
    "    maj1: \"majority_1\", maj2: \"majority_2\",\n",
    "    unsat_cx: \"unsatisfied\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>5.4 : A broader look at the clusters using the actual values instead of PCA/UMAP :</u>\n",
    "\n",
    "- This will give us a hint of what might be a course of action for certain clusters, highlighting variables that have been blurred during PCA/UMAP\n",
    "- We will have a better idea of who's who if we do not use abstract values (standardized and scaled)\n",
    "\n",
    "<i>Foreword : We will drop the cluster containing atypical/outliers customers, a cluster size of less than 1% of the dataset will either be difficult to interpret or too time and resource consuming and not cost effective at a scale that small.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_clusters(row, replacement_dict):\n",
    "    key = int(row[\"cluster_km\"])\n",
    "    return replacement_dict[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cx[\"kmeans_name\"] = df_cx.apply(func=name_clusters, args=([rename_clusters]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre drop\n",
    "\n",
    "len(df_cx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing atypical group\n",
    "\n",
    "df_cx = df_cx[df_cx[\"kmeans_name\"] != \"atypical\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post drop\n",
    "len(df_cx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>5.4.1 : Can we blend the two majorities ? If not, what are their differences ?</u>\n",
    "\n",
    "&emsp;Focusing on the big picture first, we have two majorities which seem to share a lot, but UMAP showed that several variables were significatively different. On the radar chart we can hypothesize that, because it is the involvement component that mainly differs them, we need to look at comments and ratings ratios. The ratings/satisfaction seem, although one cluster shows a minor decrease in satisfaction, the most important differences.\n",
    "<br><br>\n",
    "\n",
    "&emsp;As we saw in early visualizations, both ratios are really close to 1 or 0 (most customers only ordered once). A plot will not easily capture the difference, we might as well use the average per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Involvment :\n",
    "\n",
    "maj1_avg_comment_ratio = np.average(df_cx[df_cx[\"kmeans_name\"] == \"majority_1\"][\"comment_ratio\"].values)\n",
    "maj2_avg_comment_ratio = np.average(df_cx[df_cx[\"kmeans_name\"] == \"majority_2\"][\"comment_ratio\"].values)\n",
    "\n",
    "print(f\"maj1 average comment ratio = {maj1_avg_comment_ratio}, maj2 average comment ratio = {maj2_avg_comment_ratio}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maj1_avg_rating_ratio = np.average(df_cx[df_cx[\"kmeans_name\"] == \"majority_1\"][\"rating_ratio\"].values)\n",
    "maj2_avg_rating_ratio = np.average(df_cx[df_cx[\"kmeans_name\"] == \"majority_2\"][\"rating_ratio\"].values)\n",
    "\n",
    "print(f\"maj1 average rating ratio = {maj1_avg_rating_ratio}, maj2 average rating ratio = {maj2_avg_rating_ratio}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations :\n",
    "\n",
    "&emsp;While the average rating ratio is as expected, it seems the major factor separating the two clusters is the fact that majority 2 has not left a comment. It explains why there was a drop in the PC summarizing the general involvement. <br>\n",
    "&emsp;Let's take a look at the ratings, maybe there are more differences. If the ratings are significantly different, we will use two boxplots to get a better overall view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maj1_avg_ratings = np.average(df_cx[df_cx[\"kmeans_name\"] == \"majority_1\"][\"rating_avg\"].values)\n",
    "maj2_avg_ratings = np.average(df_cx[df_cx[\"kmeans_name\"] == \"majority_2\"][\"rating_avg\"].values)\n",
    "\n",
    "print(f\"maj1 average rating ratio = {maj1_avg_ratings}, maj2 average rating ratio = {maj2_avg_ratings}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's significant enough, let's take a broader look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1), (ax2)) = plt.subplots(\n",
    "    ncols=1,\n",
    "    nrows=2,\n",
    "    figsize=(8, 5),\n",
    "    dpi=pc_dpi,\n",
    ")\n",
    "\n",
    "ax1.boxplot(x=df_cx[df_cx[\"kmeans_name\"] == \"majority_1\"][\"rating_avg\"].values, vert=False, showmeans=True, widths=0.6)\n",
    "ax2.boxplot(x=df_cx[df_cx[\"kmeans_name\"] == \"majority_2\"][\"rating_avg\"].values, vert=False, showmeans=True, widths=0.6)\n",
    "\n",
    "\n",
    "###\n",
    "# Titles/Lables\n",
    "ax1.set(yticklabels=[])\n",
    "ax1.set(title=\"Repartition of ratings, first majority\")\n",
    "ax2.set(yticklabels=[])\n",
    "ax2.set(title=\"Repartition of ratings, second majority\")\n",
    "#\n",
    "###\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation :\n",
    "&emsp;While both ratings are high, the first majority seems to be less enthusiast than the second majority. Not enough to be an issue as ratings are well above the 2.5 mark, but it would be important to keep an eye on majority 1 to avoid a downward trend. Applying the same measures as we will recommend for the overall dissatisfied customers, although not at the same intensity, might be a way to prevent clients from majority 1 to become unsatisfied. <br><br>\n",
    "&emsp;To conclude, we cannot merge the majorities, and we also need to keep an eye on majority 1, keeping them happy and making them happier as, by their population, they represent a sizable portion of the dataset. (around 25-30%) -- Renaming customers part of maj1 to can_shift. They are not unhappy yet, but could become so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cx[\"kmeans_name\"].replace(to_replace={\"majority_1\": \"can_shift\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>5.4.2 : What causes the discontent of the unsatisfied group ?</u>\n",
    "\n",
    "- This particular cluster shows sign of discontent : lack of involvement as well as a high value for the PC we associated with unsatisfaction (and, logically, lower value in the satisfaction PC).\n",
    "- It is necessary to have a preliminary diagnostic to :\n",
    "    - Possibly shift the customers towards a better overall satisfaction\n",
    "    - Preventing customers that can_shift towards this group to do so.\n",
    "<br><br>\n",
    "\n",
    "- We will take a look at average ratings, delays and distances to try and find a pattern if it exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating repartition : \n",
    "\n",
    "fig, ((ax1), (ax2)) = plt.subplots(\n",
    "    ncols=1,\n",
    "    nrows=2,\n",
    "    figsize=(8, 5),\n",
    "    dpi=pc_dpi,\n",
    ")\n",
    "\n",
    "ax1.boxplot(x=df_cx[df_cx[\"kmeans_name\"] == \"unsatisfied\"][\"rating_avg\"].values, vert=False, showmeans=True, widths=0.6)\n",
    "ax2.boxplot(x=df_cx[\"rating_avg\"].values, vert=False, showmeans=True, widths=0.6)\n",
    "\n",
    "\n",
    "###\n",
    "# Titles/Lables\n",
    "ax1.set(yticklabels=[])\n",
    "ax1.set(title=\"Repartition of ratings, unsatisfied customers\")\n",
    "ax2.set(yticklabels=[])\n",
    "ax2.set(title=\"Repartition of ratings, dataset wide\")\n",
    "#\n",
    "###\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation :\n",
    "\n",
    "&emsp;No surprise here, it was expected from unsat. cluster to have ratings that are way lower in contrast to the rest of the dataset. It looks like the split we did (people that rated at most 2.5 in average, see #2). <br>\n",
    "&emsp;We expect higher delta days between expected and actual delivery. We will take a look at distance from seller as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the same code from #2 : \n",
    "\n",
    "amount_eot_all = len(df_cx[df_cx[\"early_on_time\"] == True])\n",
    "amount_eot_unsat = len(df_cx[(df_cx[\"early_on_time\"] == True) & (df_cx[\"kmeans_name\"] == \"unsatisfied\")])\n",
    "\n",
    "percentage_all = (amount_eot_all / len(df_cx)) * 100\n",
    "percentage_unsat = (amount_eot_unsat / len(df_cx[df_cx[\"kmeans_name\"] == \"unsatisfied\"])) * 100\n",
    "\n",
    "print(f\"There is {percentage_all}% of who have been delivered on time on the whole dataset\")\n",
    "print(f\"There is {percentage_unsat}% of who have been delivered on time or early in the unsat group\")\n",
    "\n",
    "print(f\"\"\"\n",
    "In total, {amount_eot_unsat} orders have been delivered on time or early in the unsat group,\\\n",
    " group size is {len(df_cx[df_cx[\"kmeans_name\"] == \"unsatisfied\"])}\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation :\n",
    "\n",
    "&emsp;It is safe to say that the unsatisfied customers are the ones who have been impacted by delays the most. Recommendations for this group, considering the data we have, is to offer an incentive/a compensation for the delay issue, and to address it as soon as possible to avoid general insatisfaction.\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion : \n",
    "\n",
    "&emsp;With these groups identified, it is possible to give a reliable explanation of which client is in which group. Maintenance will be done on the PCA dataset exported earlier to avoid differences. We can export the dataset containing client important info as an output, both pickle and csv will be used to maximize compatibility.\n",
    "\n",
    "<hr>\n",
    "\n",
    "Recommendations : \n",
    "- Target the dissatisfied group specifically with incentives/compensations and ensure that differences between estimated and actual delivery will be kept to a minimum, or to a negative (early delivery)\n",
    "- Majority 2 and New Customers do not necessitate any particular action, they are satisfied by their experience on Olist.\n",
    "- Majority 1's, renamed can_shift, delivery times must be kept low, actions recommended on the dissatisfied group are also recommended for this group, although not with the same intensity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cx.to_pickle(path=\"../pickles/final_clustering.pkl\")\n",
    "df_cx.to_csv(path_or_buf=\"../data/final/final_clustering.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "a2214c6fb926f71468a18ca7cf946224dc61b1c77c0f95ec2e3a3e68abe6a5ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
